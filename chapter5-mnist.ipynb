{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing mnist dataset and randomizing samples before dividing in training and testing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape: (30000, 784)\n",
      "validation sets shape: (15000, 784)\n",
      "small batch size  6000\n"
     ]
    }
   ],
   "source": [
    "#scaling the dataset and making 3 batches of training data and 2 validation sets. tr: half. rest half dividd in 2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "\n",
    "int1, int2 = int( m/2), int(m/4)\n",
    "X_tr_b1, X_tr_b2, X_tr_b3 = X_train_scaled[0:int1], X_train_scaled[int1:int1 + int2], X_train_scaled[int1 + int2:]\n",
    "\n",
    "print(\"training shape:\", X_tr_b1.shape)\n",
    "print(\"validation sets shape:\", X_tr_b2.shape)         \n",
    "\n",
    "#taking small batches to test\n",
    "x_tr = X_tr_b1[:6000]\n",
    "y_tr = y_train[:6000]\n",
    "print('small batch size ', x_tr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEARSVC: Training acc:  0.9941666666666666\n",
      "LINEARSVC: Validation acc:  0.8377333333333333\n",
      "POLY KERNEL: Training acc:  0.243\n",
      "POLY KERNEL: Validation acc:  0.20546666666666666\n",
      "RBF KERNEL: Training acc:  0.9835\n",
      "RBF KERNEL: Validation acc:  0.9304666666666667\n"
     ]
    }
   ],
   "source": [
    "#testing different technques to see which is the best estimator with limited samples of 6000\n",
    "\n",
    "#Using LinearSVC to fit and make predictions\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_linear = LinearSVC(random_state = 42, C = 0.5)\n",
    "\n",
    "svm_linear.fit(x_tr,y_tr)\n",
    "\n",
    "y_pred = svm_linear.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('LINEARSVC: Training acc: ', tr_ac)\n",
    "\n",
    "y_predv = svm_linear.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1:int1+int2], y_predv)\n",
    "print('LINEARSVC: Validation acc: ', v_ac)\n",
    "\n",
    "\n",
    "#using poly kernel with degree 3\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_poly_reg = SVC(kernel = 'poly', degree = 5,  C = 0.1, gamma = 'scale')\n",
    "svm_poly_reg.fit(x_tr, y_tr)\n",
    "\n",
    "y_pred = svm_poly_reg.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('POLY KERNEL: Training acc: ', tr_ac)\n",
    "\n",
    "y_predv = svm_poly_reg.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1:int1+int2], y_predv)\n",
    "print('POLY KERNEL: Validation acc: ', v_ac)\n",
    "\n",
    "#using rbf kernel\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale', random_state=42, decision_function_shape='ovr')\n",
    "clf.fit(x_tr, y_tr) \n",
    "\n",
    "y_pred = clf.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('RBF KERNEL: Training acc: ', tr_ac)\n",
    "\n",
    "v_sc = clf.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1 :int2 + int1], v_sc)\n",
    "print('RBF KERNEL: Validation acc: ', v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with search. now gonna fit\n",
      "adfdsf\n",
      "0.9336666666666666 {'C': 10.197786954824865, 'gamma': 0.001513186272679838}\n",
      "0.20933333333333334 {'C': 9.111710799145637, 'gamma': 0.06719156480223124}\n",
      "0.9325 {'C': 5.214011801409708, 'gamma': 0.001848939794318145}\n",
      "0.18033333333333335 {'C': 20.160792702435387, 'gamma': 0.09114265653213442}\n",
      "0.20766666666666667 {'C': 18.763705910048422, 'gamma': 0.06993087682473523}\n",
      "0.7723333333333333 {'C': 22.10471513421927, 'gamma': 0.009118854871587641}\n",
      "0.6356666666666667 {'C': 11.670464907157104, 'gamma': 0.018385511949522124}\n",
      "0.9355 {'C': 15.671068219080436, 'gamma': 0.0011263118134606108}\n",
      "0.678 {'C': 24.145943401650122, 'gamma': 0.01381957639278581}\n",
      "0.37166666666666665 {'C': 22.489835833553386, 'gamma': 0.029461872248440116}\n"
     ]
    }
   ],
   "source": [
    "#using rbf kernel with randomized search on limited dataset to get better hyperparams\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, reciprocal, uniform\n",
    "\n",
    "clf = SVC(C=0.1, kernel='rbf', random_state=42, decision_function_shape='ovr')\n",
    "\n",
    "params = {\n",
    "    'C': uniform(5 , 20),\n",
    "     'gamma':   reciprocal(0.001, 0.1)# [0.0001, 0.001, 0.5]\n",
    "}\n",
    " \n",
    "newgridsearch = RandomizedSearchCV(clf, param_distributions = params, n_iter=10, cv = 3, scoring='accuracy')#, verbose = True)\n",
    "print('done with search. now gonna fit')\n",
    "r_grid_search = newgridsearch.fit(x_tr, y_tr)\n",
    "print('adfdsf')\n",
    "r_cv = r_grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(r_cv[\"mean_test_score\"], r_cv[\"params\"]):\n",
    "    print((mean_score), params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=15.671068219080436, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0011263118134606108,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = r_grid_search.best_estimator_\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF KERNEL: Training acc:  0.9994666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred = final_model.predict(X_train_scaled)\n",
    "tr_ac = accuracy_score(y_train, y_pred)\n",
    "print('RBF KERNEL: Training acc: ', tr_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF KERNEL: Testing acc:  0.9721\n"
     ]
    }
   ],
   "source": [
    "#testing dataset\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "tr_ac = accuracy_score(y_test, y_pred)\n",
    "print('RBF KERNEL: Testing acc: ', tr_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
