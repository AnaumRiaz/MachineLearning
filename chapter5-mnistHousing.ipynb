{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing mnist dataset and randomizing samples before dividing in training and testing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '<1H OCEAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-10a17960cf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    647\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    648\u001b[0m                         \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '<1H OCEAN'"
     ]
    }
   ],
   "source": [
    "#scaling the dataset and making 3 batches of training data and 2 validation sets. tr: half. rest half dividd in 2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "\n",
    "int1, int2 = int( m/2), int(m/4)\n",
    "X_tr_b1, X_tr_b2, X_tr_b3 = X_train_scaled[0:int1], X_train_scaled[int1:int1 + int2], X_train_scaled[int1 + int2:]\n",
    "\n",
    "print(\"training shape:\", X_tr_b1.shape)\n",
    "print(\"validation sets shape:\", X_tr_b2.shape)         \n",
    "\n",
    "#taking small batches to test\n",
    "x_tr = X_tr_b1[:6000]\n",
    "y_tr = y_train[:6000]\n",
    "print('small batch size ', x_tr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEARSVC: Training acc:  0.9941666666666666\n",
      "LINEARSVC: Validation acc:  0.8377333333333333\n",
      "POLY KERNEL: Training acc:  0.243\n",
      "POLY KERNEL: Validation acc:  0.20546666666666666\n",
      "RBF KERNEL: Training acc:  0.9835\n",
      "RBF KERNEL: Validation acc:  0.9304666666666667\n"
     ]
    }
   ],
   "source": [
    "#testing different technques to see which is the best estimator with limited samples of 6000\n",
    "\n",
    "#Using LinearSVC to fit and make predictions\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_linear = LinearSVC(random_state = 42, C = 0.5)\n",
    "\n",
    "svm_linear.fit(x_tr,y_tr)\n",
    "\n",
    "y_pred = svm_linear.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('LINEARSVC: Training acc: ', tr_ac)\n",
    "\n",
    "y_predv = svm_linear.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1:int1+int2], y_predv)\n",
    "print('LINEARSVC: Validation acc: ', v_ac)\n",
    "\n",
    "\n",
    "#using poly kernel with degree 3\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_poly_reg = SVC(kernel = 'poly', degree = 5,  C = 0.1, gamma = 'scale')\n",
    "svm_poly_reg.fit(x_tr, y_tr)\n",
    "\n",
    "y_pred = svm_poly_reg.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('POLY KERNEL: Training acc: ', tr_ac)\n",
    "\n",
    "y_predv = svm_poly_reg.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1:int1+int2], y_predv)\n",
    "print('POLY KERNEL: Validation acc: ', v_ac)\n",
    "\n",
    "#using rbf kernel\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale', random_state=42, decision_function_shape='ovr')\n",
    "clf.fit(x_tr, y_tr) \n",
    "\n",
    "y_pred = clf.predict(x_tr)\n",
    "tr_ac = accuracy_score(y_tr, y_pred)\n",
    "print('RBF KERNEL: Training acc: ', tr_ac)\n",
    "\n",
    "v_sc = clf.predict(X_tr_b2)\n",
    "v_ac = accuracy_score(y_train[int1 :int2 + int1], v_sc)\n",
    "print('RBF KERNEL: Validation acc: ', v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with search. now gonna fit\n",
      "adfdsf\n",
      "0.9336666666666666 {'C': 10.197786954824865, 'gamma': 0.001513186272679838}\n",
      "0.20933333333333334 {'C': 9.111710799145637, 'gamma': 0.06719156480223124}\n",
      "0.9325 {'C': 5.214011801409708, 'gamma': 0.001848939794318145}\n",
      "0.18033333333333335 {'C': 20.160792702435387, 'gamma': 0.09114265653213442}\n",
      "0.20766666666666667 {'C': 18.763705910048422, 'gamma': 0.06993087682473523}\n",
      "0.7723333333333333 {'C': 22.10471513421927, 'gamma': 0.009118854871587641}\n",
      "0.6356666666666667 {'C': 11.670464907157104, 'gamma': 0.018385511949522124}\n",
      "0.9355 {'C': 15.671068219080436, 'gamma': 0.0011263118134606108}\n",
      "0.678 {'C': 24.145943401650122, 'gamma': 0.01381957639278581}\n",
      "0.37166666666666665 {'C': 22.489835833553386, 'gamma': 0.029461872248440116}\n"
     ]
    }
   ],
   "source": [
    "#using rbf kernel with randomized search on limited dataset to get better hyperparams\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, reciprocal, uniform\n",
    "\n",
    "clf = SVC(C=0.1, kernel='rbf', random_state=42, decision_function_shape='ovr')\n",
    "\n",
    "params = {\n",
    "    'C': uniform(5 , 20),\n",
    "     'gamma':   reciprocal(0.001, 0.1)# [0.0001, 0.001, 0.5]\n",
    "}\n",
    " \n",
    "newgridsearch = RandomizedSearchCV(clf, param_distributions = params, n_iter=10, cv = 3, scoring='accuracy')#, verbose = True)\n",
    "print('done with search. now gonna fit')\n",
    "r_grid_search = newgridsearch.fit(x_tr, y_tr)\n",
    "print('adfdsf')\n",
    "r_cv = r_grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(r_cv[\"mean_test_score\"], r_cv[\"params\"]):\n",
    "    print((mean_score), params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=15.671068219080436, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0011263118134606108,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = r_grid_search.best_estimator_\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF KERNEL: Training acc:  0.9994666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred = final_model.predict(X_train_scaled)\n",
    "tr_ac = accuracy_score(y_train, y_pred)\n",
    "print('RBF KERNEL: Training acc: ', tr_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF KERNEL: Testing acc:  0.9721\n"
     ]
    }
   ],
   "source": [
    "#testing dataset\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "tr_ac = accuracy_score(y_test, y_pred)\n",
    "print('RBF KERNEL: Testing acc: ', tr_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ Californiahousing\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "  \n",
    "HOUSING_PATH = \"datasets/housing/housing.csv\"\n",
    "\n",
    " \n",
    "def load_housing_data(housing_path = HOUSING_PATH):\n",
    "    return pd.read_csv(housing_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "mh = housing.copy()\n",
    "y = (housing[\"median_house_value\"]/100000)\n",
    "\n",
    "mh.drop(['median_house_value', 'ocean_proximity'] ,axis = 1, inplace = True)\n",
    "X = mh \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('imputing', SimpleImputer(strategy = 'median')),\n",
    "    \n",
    "])\n",
    "\n",
    "X_train_scaled = num_pipe.fit_transform(X_train)\n",
    "X_test_scaled = num_pipe.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVR MSE:  0.49756610100542215\n",
      "SVR(linear) MSE:  0.49712035321522663\n",
      "RBF SVR MSE:  0.3165258088441752\n"
     ]
    }
   ],
   "source": [
    "#linearSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg_l = LinearSVR(random_state = 42)\n",
    "reg_l.fit(X_train_scaled, y_train)\n",
    "y_pred = reg_l.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print('Linear SVR MSE: ',mse)\n",
    "\n",
    "#SVR\n",
    "from sklearn.svm import SVR\n",
    "reg_svr = SVR(kernel = 'linear', C = 1)\n",
    "reg_svr.fit(X_train_scaled, y_train)\n",
    "y_pred = reg_svr.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print('SVR(linear) MSE: ',mse)\n",
    "\n",
    "#rbf kernel\n",
    "from sklearn.svm import SVR\n",
    "reg_svr = SVR( kernel = 'rbf', C = 1)\n",
    "reg_svr.fit(X_train_scaled, y_train)\n",
    "y_pred = reg_svr.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print('RBF SVR MSE: ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2716675307031036 {'C': 29.812024447057, 'epsilon': 1e-05, 'gamma': 0.0008737339605848272}\n",
      "1.3132813313391567 {'C': 22.79918377945657, 'epsilon': 0.0001, 'gamma': 0.005914672909572354}\n",
      "1.4269802127023523 {'C': 33.21318317178179, 'epsilon': 1e-05, 'gamma': 0.000154240995784087}\n",
      "1.302880282626853 {'C': 20.320468596023233, 'epsilon': 1e-05, 'gamma': 0.0023933765933444864}\n",
      "1.3125333926264793 {'C': 28.833945975804188, 'epsilon': 0.0001, 'gamma': 0.005170349182943951}\n",
      "1.3310344011242494 {'C': 25.44572996264208, 'epsilon': 1e-05, 'gamma': 0.00022305228196174462}\n",
      "1.3212450683952635 {'C': 33.14785254498749, 'epsilon': 0.0001, 'gamma': 0.0002362960902142455}\n",
      "1.3107599940669445 {'C': 16.49300766907983, 'epsilon': 1e-05, 'gamma': 0.004153998145767329}\n",
      "1.3081567822838525 {'C': 30.176001672077557, 'epsilon': 1e-05, 'gamma': 0.003315316466483531}\n",
      "1.3102413830290973 {'C': 28.922595311477643, 'epsilon': 1e-05, 'gamma': 0.003946957578035454}\n",
      "1.2827266783350593 {'C': 15.358913572813027, 'epsilon': 1e-05, 'gamma': 0.0011655978314980846}\n",
      "1.291783381804 {'C': 18.9369528345483, 'epsilon': 0.0001, 'gamma': 0.0015235186647700833}\n",
      "1.2821651973871568 {'C': 34.54128950322601, 'epsilon': 0.0001, 'gamma': 0.0011477500814873062}\n",
      "1.3006576322335064 {'C': 34.708480979634714, 'epsilon': 1e-05, 'gamma': 0.00026499092681871633}\n",
      "1.3307615591402195 {'C': 33.461369846139725, 'epsilon': 1e-05, 'gamma': 0.0002257926040868313}\n",
      "1.2869952743105117 {'C': 20.446869505352836, 'epsilon': 0.0001, 'gamma': 0.0002876345029850439}\n",
      "1.268538289518292 {'C': 33.59535327273753, 'epsilon': 0.0001, 'gamma': 0.0008042539550401384}\n",
      "1.308159632912172 {'C': 24.078980246929486, 'epsilon': 1e-05, 'gamma': 0.003316064662559317}\n",
      "1.2951006193671364 {'C': 29.323432034016427, 'epsilon': 1e-05, 'gamma': 0.0017092040432618164}\n",
      "1.28888078458655 {'C': 26.851068492771113, 'epsilon': 0.0001, 'gamma': 0.0013898202790410775}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, reciprocal, uniform\n",
    "\n",
    "params = {\n",
    "    'C': uniform(15 , 20),\n",
    "     'gamma':   reciprocal(0.0001, 0.01),# [0.0001, 0.001, 0.5]\n",
    "    'epsilon' : [0.00001, 0.0001]\n",
    "}\n",
    " \n",
    "newgridsearch = RandomizedSearchCV(reg_svr, param_distributions = params, n_iter=20, cv = 3, scoring = \"neg_mean_squared_error\")#, verbose = True)\n",
    "r_grid_search = newgridsearch.fit(X_train[:2000], y_train[:2000])\n",
    "\n",
    "r_cv = r_grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(r_cv[\"mean_test_score\"], r_cv[\"params\"]):\n",
    "    print(-(mean_score), params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=25.2848007410704, cache_size=200, coef0=0.0, degree=3, epsilon=1e-05,\n",
       "  gamma=0.00050990606601943, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = r_grid_search.best_estimator_\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred = final_model.predict(X_train_scaled)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print('Training: RBF SVR MSE after randomizedsearch: ',mse)\n",
    "\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Testing: RBF SVR MSE after randomizedsearch: ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.949968822217229"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
