{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
      "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TITANIC_PATH = \"datasets/Titanic/train.csv\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_titanic_data(titanic_path = TITANIC_PATH):\n",
    "    return pd.read_csv(TITANIC_PATH)\n",
    "\n",
    "tit_data = load_titanic_data()\n",
    "#print(tit_data.info)\n",
    "\n",
    "#separating labels and training, randomizing the sequence of the samples\n",
    "tit_data2 = tit_data.copy()\n",
    "X_train_df = (tit_data2.drop([\"Survived\", \"Name\"], axis = 1))\n",
    "X_train = X_train_df.values\n",
    "y_train = (tit_data[\"Survived\"]).values\n",
    "shuffle_index = np.random.permutation(891)    #0 to 890\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "\n",
    "cols = X_train_df.columns\n",
    "X_train = pd.DataFrame(X_train, columns = cols)\n",
    "\n",
    "\n",
    "#making dummy variables for the string features\n",
    "string_feats = X_train.iloc[:, [2, 9]]\n",
    "gd = pd.get_dummies(string_feats, prefix = ['Sex', 'Embarked'])\n",
    "\n",
    "\n",
    "#joining dummies and originals\n",
    "X_train.drop([\"Sex\", \"Embarked\", \"Cabin\", \"Ticket\"], axis = 1, inplace = True)\n",
    "X_train = pd.concat([X_train, gd], axis = 1 )\n",
    "\n",
    "\n",
    "#putting median age in the Nans\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = imp_med.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_imp, columns = X_train.columns)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SGD non scaled) [0.63299663 0.61952862 0.67003367]\n",
      "(SGD scaled) [0.71380471 0.75420875 0.74410774]\n",
      "(Random Forest unscaled) [0.81144781 0.82154882 0.81481481]\n",
      "(Random Forest scaled) [0.8047138  0.83501684 0.81818182]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_train[\"fam_size\"] = X_train[\"SibSp\"] + X_train[\"Parch\"]\n",
    "# X_train.drop([\"PassengerId\", \"SibSp\", \"Parch\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_scrs = cross_val_score(sgd_clf, X_train, y_train, cv = 3, scoring = \"accuracy\")\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "print(\"(SGD non scaled)\", sgd_scrs)\n",
    "\n",
    "#using standard scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "sgd_scrs_scaled = cross_val_score(sgd_clf, X_train_scaled, y_train, cv = 3, scoring = \"accuracy\")\n",
    "print(\"(SGD scaled)\", sgd_scrs_scaled)\n",
    "\n",
    "#using randomforestclassifier unscaled\n",
    "forest_clf = RandomForestClassifier(random_state = 42)\n",
    "frst_scrs = cross_val_score(forest_clf, X_train, y_train, cv = 3, scoring = \"accuracy\")\n",
    "print(\"(Random Forest unscaled)\", frst_scrs)\n",
    "\n",
    "#using randomforestclassifier scaled\n",
    "forest_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "frst_scrs = cross_val_score(forest_clf, X_train_scaled, y_train, cv = 3, scoring = \"accuracy\")\n",
    "print(\"(Random Forest scaled)\", frst_scrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "     PassengerId  Pclass    Age  SibSp  Parch      Fare  Sex_female  Sex_male  \\\n",
      "29           8.0     3.0   2.00    3.0    1.0   21.0750         0.0       1.0   \n",
      "51         825.0     3.0   2.00    4.0    1.0   39.6875         0.0       1.0   \n",
      "64         643.0     3.0   2.00    3.0    2.0   27.9000         1.0       0.0   \n",
      "82         306.0     1.0   0.92    1.0    2.0  151.5500         0.0       1.0   \n",
      "216        165.0     3.0   1.00    4.0    1.0   39.6875         0.0       1.0   \n",
      "234        120.0     3.0   2.00    4.0    2.0   31.2750         1.0       0.0   \n",
      "330        880.0     1.0  56.00    0.0    1.0   83.1583         1.0       0.0   \n",
      "374        269.0     1.0  58.00    0.0    1.0  153.4625         1.0       0.0   \n",
      "490        298.0     1.0   2.00    1.0    2.0  151.5500         1.0       0.0   \n",
      "597        387.0     3.0   1.00    5.0    2.0   46.9000         0.0       1.0   \n",
      "603         17.0     3.0   2.00    4.0    1.0   29.1250         0.0       1.0   \n",
      "651        588.0     1.0  60.00    1.0    1.0   79.2000         0.0       1.0   \n",
      "844        660.0     1.0  58.00    0.0    2.0  113.2750         0.0       1.0   \n",
      "847        439.0     1.0  64.00    1.0    4.0  263.0000         0.0       1.0   \n",
      "889        746.0     1.0  70.00    1.0    1.0   71.0000         0.0       1.0   \n",
      "62         847.0     3.0  28.00    8.0    2.0   69.5500         0.0       1.0   \n",
      "97         160.0     3.0  28.00    8.0    2.0   69.5500         0.0       1.0   \n",
      "100         28.0     1.0  19.00    3.0    2.0  263.0000         0.0       1.0   \n",
      "135        793.0     3.0  28.00    8.0    2.0   69.5500         1.0       0.0   \n",
      "335        181.0     3.0  28.00    8.0    2.0   69.5500         1.0       0.0   \n",
      "358        342.0     1.0  24.00    3.0    2.0  263.0000         1.0       0.0   \n",
      "444        864.0     3.0  28.00    8.0    2.0   69.5500         1.0       0.0   \n",
      "721        202.0     3.0  28.00    8.0    2.0   69.5500         0.0       1.0   \n",
      "861         89.0     1.0  23.00    3.0    2.0  263.0000         1.0       0.0   \n",
      "876        325.0     3.0  28.00    8.0    2.0   69.5500         0.0       1.0   \n",
      "\n",
      "     Embarked_C  Embarked_Q  Embarked_S  \n",
      "29          0.0         0.0         1.0  \n",
      "51          0.0         0.0         1.0  \n",
      "64          0.0         0.0         1.0  \n",
      "82          0.0         0.0         1.0  \n",
      "216         0.0         0.0         1.0  \n",
      "234         0.0         0.0         1.0  \n",
      "330         1.0         0.0         0.0  \n",
      "374         0.0         0.0         1.0  \n",
      "490         0.0         0.0         1.0  \n",
      "597         0.0         0.0         1.0  \n",
      "603         0.0         1.0         0.0  \n",
      "651         1.0         0.0         0.0  \n",
      "844         1.0         0.0         0.0  \n",
      "847         0.0         0.0         1.0  \n",
      "889         0.0         0.0         1.0  \n",
      "62          0.0         0.0         1.0  \n",
      "97          0.0         0.0         1.0  \n",
      "100         0.0         0.0         1.0  \n",
      "135         0.0         0.0         1.0  \n",
      "335         0.0         0.0         1.0  \n",
      "358         0.0         0.0         1.0  \n",
      "444         0.0         0.0         1.0  \n",
      "721         0.0         0.0         1.0  \n",
      "861         0.0         0.0         1.0  \n",
      "876         0.0         0.0         1.0  \n",
      "(866, 11)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(X_train.shape)\n",
    "\n",
    "#removing otliers from the data\n",
    "def remove_outlier_rows(f_name_array, given_number):\n",
    "    outlier_cols = []\n",
    "    \n",
    "    for one_col in f_name_array:\n",
    "        P1 = np.percentile(X_train[one_col], 25)\n",
    "        P2 = np.percentile(X_train[one_col], 75)\n",
    "        IQR = P2 - P1\n",
    "        outlier_step = 1.5 * IQR\n",
    "       \n",
    "        indices_outlier_rows = X_train[(X_train[one_col] > P2 + outlier_step) | (X_train[one_col] < P1 - outlier_step)].index\n",
    "        #print(X_train[(X_train[one_col] > P2 + IQR) | (X_train[one_col] < P1 - IQR)])\n",
    "        outlier_cols.extend(indices_outlier_rows)\n",
    "       \n",
    "    check = Counter(outlier_cols)\n",
    "    \n",
    "    rows_to_remove = [k for k,v in check.items() if v > given_number]\n",
    "    #print((rows_to_remove))\n",
    "    print(X_train.loc[rows_to_remove]) # Show the outliers rows\n",
    "\n",
    "    X_train.drop(rows_to_remove, inplace = True)\n",
    "\n",
    "remove_outlier_rows([\"Age\", \"Parch\", \"SibSp\", \"Fare\"], 2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    print(multiple_outliers)\n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(X_train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
