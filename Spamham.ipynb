{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "datasets/spamham/easy_spam/mail_0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-f7f81fd3b5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mmy_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree\n",
    "import mailbox   \n",
    "import lxml.html\n",
    "import lxml.html.clean\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "#Giving filepaths for the data\n",
    "dat_path = \"datasets/spamham\"\n",
    "spam_path = dat_path + '/easy_spam'\n",
    "ham_path = dat_path + '/easy_ham'\n",
    "ar_dict = [(spam_path, 501)] #, {ham_path,2551}] 501\n",
    "words_mails = []\n",
    "\n",
    "for sp, num in ar_dict:\n",
    "    tr_n = math.ceil(0.8 * int(num))\n",
    "    print(tr_n)\n",
    "    \n",
    "    for file_num in range(tr_n):\n",
    "        #Reading an email and getting the content\n",
    "        email = spam_PATH + '/mail_' + str(file_num)\n",
    "        print(email)\n",
    "        mbox = mailbox.mbox(email)\n",
    "\n",
    "        for message in mbox:\n",
    "           #print(message.keys())\n",
    "            #print(message['Subject'])\n",
    "            if message.is_multipart():\n",
    "                \n",
    "                content = ''.join(part.get_payload(decode=False) for part in message.get_payload())\n",
    "                my_str = str(content.astype(int), encoding='utf-8')\n",
    "            else:\n",
    "                content = message.get_payload(decode=True)\n",
    "               \n",
    "        print(content)\n",
    "        #num_urls = counting_urls(content)\n",
    "        #pd_in = preparing_data()\n",
    "        #l = pd_in.transform(content)\n",
    "        #words_mails.append(l)\n",
    "        #print(len(words_mails))\n",
    "            \n",
    "\n",
    "                \n",
    "class preparing_data(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x, y=None):\n",
    "        x.lower()\n",
    "        x = cleaning_htmlent(x)\n",
    "        \n",
    "        content_words =  TreebankWordTokenizer().tokenize(content)\n",
    "        ps = PorterStemmer()\n",
    "        f_c =   [ps.stem(w) for w in content_words]\n",
    "        \n",
    "        return f_c\n",
    "        \n",
    "\n",
    "\n",
    "def cleaning_htmlent(text):\n",
    "    doc = lxml.html.fromstring(text)\n",
    "    cleaner = lxml.html.clean.Cleaner(style=True)\n",
    "    doc = cleaner.clean_html(doc)\n",
    "    content = doc.text_content()\n",
    "    return content\n",
    "\n",
    "def counting_urls(text):\n",
    "#     soup = BeautifulSoup(text, 'html.parser')\n",
    "#     num = soup.find_all('a')\n",
    "#     print('number is ', (num))\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    num_urls = len(urls)\n",
    "    return num_urls\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding str is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-2ee0df86ff88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'anahdfad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: decoding str is not supported"
     ]
    }
   ],
   "source": [
    "name = 'anahdfad'\n",
    "str(name, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
